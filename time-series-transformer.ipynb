{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-18T14:17:34.416330Z","iopub.execute_input":"2023-04-18T14:17:34.416883Z","iopub.status.idle":"2023-04-18T14:17:34.430650Z","shell.execute_reply.started":"2023-04-18T14:17:34.416825Z","shell.execute_reply":"2023-04-18T14:17:34.429417Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q yfinance","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:17:34.432877Z","iopub.execute_input":"2023-04-18T14:17:34.433922Z","iopub.status.idle":"2023-04-18T14:17:47.861616Z","shell.execute_reply.started":"2023-04-18T14:17:34.433881Z","shell.execute_reply":"2023-04-18T14:17:47.860046Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import yfinance as yf\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import MinMaxScaler\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Download Tesla stock data from 2018 to 2022\nticker = \"TSLA\"\nstart_date = \"2018-01-01\"\nend_date = \"2022-12-31\"\n\ndata = yf.download(ticker, start=start_date, end=end_date)\nclose_prices = data[\"Close\"].values.reshape(-1, 1)\n\n# Normalize the data\nscaler = MinMaxScaler()\nnormalized_close_prices = scaler.fit_transform(close_prices)\n\n# Create the input and target data\nsequence_length = 180\ninput_data = []\ntarget_data = []\n\nfor i in range(len(normalized_close_prices) - sequence_length):\n    input_data.append(normalized_close_prices[i:i+sequence_length])\n    target_data.append(normalized_close_prices[i+sequence_length])\n\ninput_data = torch.tensor(input_data).float()\ntarget_data = torch.tensor(target_data).float()\n\n# Create DataLoader\ndataset = TensorDataset(input_data, target_data)\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\n# Define the MultiHeadSelfAttention module\nclass MultiHeadSelfAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadSelfAttention, self).__init__()\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.head_dim = d_model // num_heads\n\n        self.Wq = nn.Linear(d_model, d_model)\n        self.Wk = nn.Linear(d_model, d_model)\n        self.Wv = nn.Linear(d_model, d_model)\n\n        self.Wo = nn.Linear(d_model, d_model)\n\n    def forward(self, x):\n        N, T, E = x.size()\n\n        q = self.Wq(x)\n        k = self.Wk(x)\n        v = self.Wv(x)\n\n        q = q.view(N, T, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n        k = k.view(N, T, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n        v = v.view(N, T, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n\n        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (E ** (1/2))\n        attn_probs = torch.softmax(attn_scores, dim=-1)\n        attn_output = torch.matmul(attn_probs, v)\n\n        attn_output = attn_output.permute(0, 2, 1, 3).contiguous().view(N, T, E)\n        output = self.Wo(attn_output)\n\n        return output\n\n# Define the TimeSeriesTransformerEncoder model\nclass TimeSeriesTransformerEncoder(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(TimeSeriesTransformerEncoder, self).__init__()\n\n        self.self_attention = MultiHeadSelfAttention(d_model, num_heads)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.ff = nn.Sequential(\n            nn.Linear(d_model, d_model * 4),\n            nn.ReLU(),\n            nn.Linear(d_model * 4, d_model)\n        )\n        self.norm2 = nn.LayerNorm(d_model)\n\n    def forward(self, x):\n        attn_output = self.self_attention(x)\n        x = self.norm1(x + attn_output)\n        ff_output = self.ff(x)\n        x = self.norm2(x + ff_output)\n        return x\n\nclass TimeSeriesPredictor(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(TimeSeriesPredictor, self).__init__()\n        self.embedding = nn.Linear(1, d_model)\n        self.encoder = TimeSeriesTransformerEncoder(d_model, num_heads)\n        self.fc = nn.Linear(d_model, 1)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = self.encoder(x)\n        x = self.fc(x[:, -1])\n        return x\n\n# Instantiate the TimeSeriesPredictor\nd_model = 64\nnum_heads = 8\npredictor = TimeSeriesPredictor(d_model, num_heads)\n\n# Define the loss function and optimizer\nloss_function = nn.MSELoss()\noptimizer = optim.Adam(predictor.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    for inputs, targets in dataloader:\n        optimizer.zero_grad()\n        outputs = predictor(inputs)\n        loss = loss_function(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n    if (epoch + 1) % 10 == 0:\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n\n# Forecasting\nlast_sequence = torch.tensor(normalized_close_prices[-sequence_length:]).float().unsqueeze(0)\npredicted_normalized_price = predictor(last_sequence)\npredicted_price = scaler.inverse_transform(predicted_normalized_price.detach().numpy())\n\nprint(f\"Predicted close price for the next day: {predicted_price[0][0]:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:17:47.866104Z","iopub.execute_input":"2023-04-18T14:17:47.866475Z","iopub.status.idle":"2023-04-18T14:23:09.700212Z","shell.execute_reply.started":"2023-04-18T14:17:47.866441Z","shell.execute_reply":"2023-04-18T14:23:09.698977Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[*********************100%***********************]  1 of 1 completed\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/100], Loss: 0.0005\nEpoch [20/100], Loss: 0.0003\nEpoch [30/100], Loss: 0.0004\nEpoch [40/100], Loss: 0.0008\nEpoch [50/100], Loss: 0.0003\nEpoch [60/100], Loss: 0.0006\nEpoch [70/100], Loss: 0.0006\nEpoch [80/100], Loss: 0.0002\nEpoch [90/100], Loss: 0.0003\nEpoch [100/100], Loss: 0.0002\nPredicted close price for the next day: 133.11\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Function to forecast next `num_days` closing prices\ndef forecast(predictor, input_sequence, num_days):\n    forecasted_prices = []\n\n    for _ in range(num_days):\n        predicted_normalized_price = predictor(input_sequence)\n        forecasted_prices.append(predicted_normalized_price.item())\n        next_input = torch.cat((input_sequence[0, 1:], predicted_normalized_price.unsqueeze(1)), dim=1)\n        input_sequence = next_input.unsqueeze(0)\n\n    return np.array(forecasted_prices)\n\n# Forecasting for the next six months (roughly 180 days)\nnum_days_to_forecast = 180\nlast_sequence = torch.tensor(normalized_close_prices[-sequence_length:]).float().unsqueeze(0)\nforecasted_normalized_prices = forecast(predictor, last_sequence, num_days_to_forecast)\n\n# Inverse transform the normalized prices to actual prices\nforecasted_prices = scaler.inverse_transform(forecasted_normalized_prices.reshape(-1, 1))\n\nprint(\"Forecasted close prices for the next six months (180 days):\")\nfor i, price in enumerate(forecasted_prices):\n    print(f\"Day {i + 1}: {price[0]:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:25:40.752343Z","iopub.execute_input":"2023-04-18T14:25:40.753834Z","iopub.status.idle":"2023-04-18T14:25:40.802380Z","shell.execute_reply.started":"2023-04-18T14:25:40.753769Z","shell.execute_reply":"2023-04-18T14:25:40.800647Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/43083811.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnum_days_to_forecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mlast_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_close_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mforecasted_normalized_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_days_to_forecast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Inverse transform the normalized prices to actual prices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/43083811.py\u001b[0m in \u001b[0;36mforecast\u001b[0;34m(predictor, input_sequence, num_days)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpredicted_normalized_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mforecasted_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_normalized_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mnext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_normalized_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"],"ename":"RuntimeError","evalue":"Tensors must have same number of dimensions: got 2 and 3","output_type":"error"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport yfinance as yf\n\n# Fetch the dataset and preprocess it\ntesla_stock = yf.Ticker(\"TSLA\")\ndata = tesla_stock.history(start=\"2018-01-01\", end=\"2022-12-31\")\nclose_prices = data['Close'].values.reshape(-1, 1)\n\n# Normalize the close prices\nscaler = MinMaxScaler(feature_range=(0, 1))\nnormalized_close_prices = scaler.fit_transform(close_prices)\n\n# Define the create_sequences function\ndef create_sequences(data, sequence_length):\n    inputs, targets = [], []\n    for i in range(len(data) - sequence_length):\n        inputs.append(data[i:i + sequence_length])\n        targets.append(data[i + sequence_length])\n    return np.array(inputs), np.array(targets)\n\n# Prepare the training and validation sets\nsequence_length = 60\ninputs, targets = create_sequences(normalized_close_prices, sequence_length)\ntrain_size = int(len(inputs) * 0.8)\ntrain_inputs, train_targets = torch.tensor(inputs[:train_size]).float(), torch.tensor(targets[:train_size]).float()\nval_inputs, val_targets = torch.tensor(inputs[train_size:]).float(), torch.tensor(targets[train_size:]).float()\n\n# DataLoader for the training set\ntrain_data = torch.utils.data.TensorDataset(train_inputs, train_targets)\ndataloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n\n# Define the TimeSeriesTransformerEncoder and other necessary classes here\n# (The classes should be the same as in the previous responses)\n\n# Instantiate the TimeSeriesPredictor\nd_model = 64\nnum_heads = 8\npredictor = TimeSeriesPredictor(d_model, num_heads)\n\n# Define the loss function and optimizer\nloss_function = nn.MSELoss()\noptimizer = optim.Adam(predictor.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    for inputs, targets in dataloader:\n        optimizer.zero_grad()\n        outputs = predictor(inputs)\n        loss = loss_function(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n    if (epoch + 1) % 10 == 0:\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n\n# Forecasting for the first three months of 2023 (roughly 90 days)\nnum_days_to_forecast = 90\nlast_sequence = torch.tensor(normalized_close_prices[-sequence_length:]).float()\nforecasted_normalized_prices = forecast(predictor, last_sequence, num_days_to_forecast)\n\n# Inverse transform the normalized prices to actual prices\nforecasted_prices = scaler.inverse_transform(forecasted_normalized_prices.reshape(-1, 1))\n\n# Fetch the true values for the first three months of 2023\ndata_2023 = tesla_stock.history(start=\"2023-01-01\", end=\"2023-03-31\")\ntrue_values = data_2023['Close'].values\n\n# Ensure that the true_values and forecasted_prices arrays have the same length\nmin_length = min(len(true_values), len(forecasted_prices))\ntrue_values = true_values[:min_length]\nforecasted_prices = forecasted_prices[:min_length]\n\n# Calculate RMSE and MAE\nrmse = np.sqrt(mean_squared_error(true_values, forecasted_prices))\nmae = mean_absolute_error(true_values, forecasted_prices)\n\nprint(f\"RMSE: {rmse:.2f}\")\nprint(f\"MAE: {mae:.2f}\")\n\n# Print the forecasted and true closing prices\nprint(\"\\nForecasted and true closing prices for the first three months of 2023:\")\nfor i, (forecasted, true) in enumerate(zip(forecasted_prices, true_values)):\n    print(f\"Day {i + 1}: {forecasted[0]:.2f} (forecasted), {true:.2f} (true)\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:23:09.948098Z","iopub.status.idle":"2023-04-18T14:23:09.948862Z","shell.execute_reply.started":"2023-04-18T14:23:09.948615Z","shell.execute_reply":"2023-04-18T14:23:09.948647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def forecast(model, initial_sequence, num_days_to_forecast):\n    model.eval()\n    current_sequence = initial_sequence.unsqueeze(0)\n    forecasted_prices = []\n\n    with torch.no_grad():\n        for _ in range(num_days_to_forecast):\n            prediction = model(current_sequence)\n            forecasted_prices.append(prediction[0, -1].item())\n\n            current_sequence = torch.cat([current_sequence[:, 1:], prediction.unsqueeze(1)], dim=1)\n\n    return np.array(forecasted_prices)","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:23:09.950696Z","iopub.status.idle":"2023-04-18T14:23:09.951113Z","shell.execute_reply.started":"2023-04-18T14:23:09.950913Z","shell.execute_reply":"2023-04-18T14:23:09.950935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forecasted_prices","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:23:09.952663Z","iopub.status.idle":"2023-04-18T14:23:09.953045Z","shell.execute_reply.started":"2023-04-18T14:23:09.952856Z","shell.execute_reply":"2023-04-18T14:23:09.952877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot the true and forecasted closing prices\nplt.plot(true_values, label=\"True Values\", color='blue')\nplt.plot(forecasted_prices, label=\"Predicted Values\", color='red', linestyle='--')\nplt.xlabel(\"Days\")\nplt.ylabel(\"Closing Price\")\nplt.title(\"Tesla Closing Price Forecast (First 3 Months of 2023)\")\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:23:09.954451Z","iopub.status.idle":"2023-04-18T14:23:09.954851Z","shell.execute_reply.started":"2023-04-18T14:23:09.954661Z","shell.execute_reply":"2023-04-18T14:23:09.954681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forecast_dates.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:23:09.956945Z","iopub.status.idle":"2023-04-18T14:23:09.957493Z","shell.execute_reply.started":"2023-04-18T14:23:09.957152Z","shell.execute_reply":"2023-04-18T14:23:09.957175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.date_range(start=data.index[-1] + pd.DateOffset(1), periods=num_days_to_forecast, freq='B')","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:23:09.958684Z","iopub.status.idle":"2023-04-18T14:23:09.959110Z","shell.execute_reply.started":"2023-04-18T14:23:09.958901Z","shell.execute_reply":"2023-04-18T14:23:09.958926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.index[-1] ","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:23:09.960553Z","iopub.status.idle":"2023-04-18T14:23:09.961495Z","shell.execute_reply.started":"2023-04-18T14:23:09.961274Z","shell.execute_reply":"2023-04-18T14:23:09.961300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create an array with dates for the forecasted period\nforecast_dates = pd.date_range(start=data.index[-1] + pd.DateOffset(1), periods=min_length, freq='B')\n\n# Combine the real prices and forecasted prices into one DataFrame\nreal_prices = data[\"Close\"]\nforecasted_prices_df = pd.DataFrame(forecasted_prices, index=forecast_dates, columns=[\"Close\"])\nall_prices = pd.concat([real_prices, forecasted_prices_df])\n\n# Plot the train, validation, and forecasted closing prices\nplt.figure(figsize=(14, 6))\n\n# Train values (2018 to 2022)\nplt.plot(data.index[:train_size], data[\"Close\"].iloc[:train_size], label=\"Train Values\", color='blue')\n\n# Validation values (remaining values in 2018 to 2022)\nplt.plot(data.index[train_size:-sequence_length], data[\"Close\"].iloc[train_size:-sequence_length], label=\"Validation Values\", color='green')\n\n# Forecasted values (first 3 months of 2023)\nplt.plot(forecast_dates, forecasted_prices, label=\"Forecasted Values\", color='red', linestyle='--')\n\nplt.xlabel(\"Date\")\nplt.ylabel(\"Closing Price\")\nplt.title(\"Tesla Closing Price (2018 to First 3 Months of 2023)\")\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T14:23:09.962984Z","iopub.status.idle":"2023-04-18T14:23:09.963410Z","shell.execute_reply.started":"2023-04-18T14:23:09.963193Z","shell.execute_reply":"2023-04-18T14:23:09.963217Z"},"trusted":true},"execution_count":null,"outputs":[]}]}