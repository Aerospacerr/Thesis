{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aerospacer/time-series?scriptVersionId=126287374\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"#https://www.kaggle.com/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs/code?datasetId=4538&sortBy=voteCount\n\n#https://www.kaggle.com/code/janiobachmann/s-p-500-time-series-forecasting-with-prophet\n\n#https://www.kaggle.com/code/faressayah/stock-market-analysis-prediction-using-lstm\n\n#https://www.kaggle.com/code/prashant111/complete-guide-on-time-series-analysis-in-python\n\n#https://www.kaggle.com/code/shreyasajal/pytorch-forecasting-for-time-series-forecasting","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:06.805943Z","iopub.execute_input":"2023-04-17T19:46:06.806411Z","iopub.status.idle":"2023-04-17T19:46:06.838683Z","shell.execute_reply.started":"2023-04-17T19:46:06.806348Z","shell.execute_reply":"2023-04-17T19:46:06.837682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nEncoder input layer : nn.Linear()\nPositional encoding layer : custom class inheriting from nn.Module\nEncoder layer : nn.TransformerEncoderLayer()\nEncoder : nn.TransformerEncoder()\nDecoder input layer : nn.Linear()\nDecoder layer : nn.TransformerDecoderLayer()\nDecoder : nn.TransformerDecoder()\nLinear mapping : nn.Linear()\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:06.840745Z","iopub.execute_input":"2023-04-17T19:46:06.842087Z","iopub.status.idle":"2023-04-17T19:46:06.858186Z","shell.execute_reply.started":"2023-04-17T19:46:06.842022Z","shell.execute_reply":"2023-04-17T19:46:06.856655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q yfinance","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:06.860505Z","iopub.execute_input":"2023-04-17T19:46:06.861028Z","iopub.status.idle":"2023-04-17T19:46:20.871502Z","shell.execute_reply.started":"2023-04-17T19:46:06.860977Z","shell.execute_reply":"2023-04-17T19:46:20.869945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# For reading stock data from yahoo\nfrom pandas_datareader.data import DataReader\nimport yfinance as yf\nfrom pandas_datareader import data as pdr\n\nyf.pdr_override()\n\n# For time stamps\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:20.874968Z","iopub.execute_input":"2023-04-17T19:46:20.875814Z","iopub.status.idle":"2023-04-17T19:46:21.895771Z","shell.execute_reply.started":"2023-04-17T19:46:20.875756Z","shell.execute_reply":"2023-04-17T19:46:21.89444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yf\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:21.89724Z","iopub.execute_input":"2023-04-17T19:46:21.897823Z","iopub.status.idle":"2023-04-17T19:46:21.90576Z","shell.execute_reply.started":"2023-04-17T19:46:21.897781Z","shell.execute_reply":"2023-04-17T19:46:21.904265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The tech stocks we'll use for this analysis\ntech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN','TSLA']\n\n# Set up End and Start times for data grab\nend = datetime.now()\nstart = datetime(end.year - 1, end.month, end.day)\n\nfor stock in tech_list:\n    globals()[stock] = yf.download(stock, start, end)\n    \n\ncompany_list = [AAPL, GOOG, MSFT, AMZN, TSLA]\ncompany_name = [\"APPLE\", \"GOOGLE\", \"MICROSOFT\", \"AMAZON\",\"TESLA\"]\n\nfor company, com_name in zip(company_list, company_name):\n    company[\"company_name\"] = com_name\n    \ndf = pd.concat(company_list, axis=0)\ndf.tail(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:21.907246Z","iopub.execute_input":"2023-04-17T19:46:21.907585Z","iopub.status.idle":"2023-04-17T19:46:23.005871Z","shell.execute_reply.started":"2023-04-17T19:46:21.907552Z","shell.execute_reply":"2023-04-17T19:46:23.004318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:23.007348Z","iopub.execute_input":"2023-04-17T19:46:23.007713Z","iopub.status.idle":"2023-04-17T19:46:23.030375Z","shell.execute_reply.started":"2023-04-17T19:46:23.007679Z","shell.execute_reply":"2023-04-17T19:46:23.028648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:23.031964Z","iopub.execute_input":"2023-04-17T19:46:23.032318Z","iopub.status.idle":"2023-04-17T19:46:23.056517Z","shell.execute_reply.started":"2023-04-17T19:46:23.032284Z","shell.execute_reply":"2023-04-17T19:46:23.055459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:23.058833Z","iopub.execute_input":"2023-04-17T19:46:23.059845Z","iopub.status.idle":"2023-04-17T19:46:23.096502Z","shell.execute_reply.started":"2023-04-17T19:46:23.059791Z","shell.execute_reply":"2023-04-17T19:46:23.0947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TSLA.describe()\n#We have only 255 records in one year because weekends are not included in the data.","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:23.101331Z","iopub.execute_input":"2023-04-17T19:46:23.101804Z","iopub.status.idle":"2023-04-17T19:46:23.137706Z","shell.execute_reply.started":"2023-04-17T19:46:23.101755Z","shell.execute_reply":"2023-04-17T19:46:23.136593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ma_day = [10, 20, 50]\n\nfor ma in ma_day:\n    for company in company_list:\n        column_name = f\"MA for {ma} days\"\n        company[column_name] = company['Adj Close'].rolling(ma).mean()\n        \n\nfig = plt.figure()\nfig.set_figheight(10)\nfig.set_figwidth(15)\n\nTSLA[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot()\n#fig.set_title('TESLA')\n\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:23.139014Z","iopub.execute_input":"2023-04-17T19:46:23.140117Z","iopub.status.idle":"2023-04-17T19:46:23.597843Z","shell.execute_reply.started":"2023-04-17T19:46:23.140067Z","shell.execute_reply":"2023-04-17T19:46:23.596555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction\n\n# Get the stock quote\ndf = pdr.get_data_yahoo('TSLA', start='2018-01-01', end='2023-01-01')\n# Show teh data\ndf","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:23.599563Z","iopub.execute_input":"2023-04-17T19:46:23.600099Z","iopub.status.idle":"2023-04-17T19:46:23.729388Z","shell.execute_reply.started":"2023-04-17T19:46:23.600037Z","shell.execute_reply":"2023-04-17T19:46:23.727966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title('Close Price History')\nplt.plot(df['Close'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:23.731101Z","iopub.execute_input":"2023-04-17T19:46:23.731565Z","iopub.status.idle":"2023-04-17T19:46:24.055323Z","shell.execute_reply.started":"2023-04-17T19:46:23.731515Z","shell.execute_reply":"2023-04-17T19:46:24.053825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new dataframe with only the 'Close column \ndata = df.filter(['Close'])\n# Convert the dataframe to a numpy array\ndataset = data.values\n# Get the number of rows to train the model on\ntraining_data_len = int(np.ceil( len(dataset) * .80 ))\n\ntraining_data_len","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:24.057109Z","iopub.execute_input":"2023-04-17T19:46:24.05752Z","iopub.status.idle":"2023-04-17T19:46:24.067365Z","shell.execute_reply.started":"2023-04-17T19:46:24.057481Z","shell.execute_reply":"2023-04-17T19:46:24.065795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:24.068764Z","iopub.execute_input":"2023-04-17T19:46:24.069175Z","iopub.status.idle":"2023-04-17T19:46:24.085449Z","shell.execute_reply.started":"2023-04-17T19:46:24.069131Z","shell.execute_reply":"2023-04-17T19:46:24.084091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:24.086435Z","iopub.execute_input":"2023-04-17T19:46:24.086817Z","iopub.status.idle":"2023-04-17T19:46:24.098257Z","shell.execute_reply.started":"2023-04-17T19:46:24.086783Z","shell.execute_reply":"2023-04-17T19:46:24.09704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the data\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:24.099678Z","iopub.execute_input":"2023-04-17T19:46:24.100029Z","iopub.status.idle":"2023-04-17T19:46:24.185218Z","shell.execute_reply.started":"2023-04-17T19:46:24.099997Z","shell.execute_reply":"2023-04-17T19:46:24.183816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:24.186885Z","iopub.execute_input":"2023-04-17T19:46:24.18795Z","iopub.status.idle":"2023-04-17T19:46:24.195209Z","shell.execute_reply.started":"2023-04-17T19:46:24.1879Z","shell.execute_reply":"2023-04-17T19:46:24.194329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the training data set \n# Create the scaled training data set\ntrain_data = scaled_data[0:int(training_data_len), :]\n# Split the data into x_train and y_train data sets\nx_train = []\ny_train = []\n\nfor i in range(60, len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i, 0])\n\n        \n# Convert the x_train and y_train to numpy arrays \nx_train, y_train = np.array(x_train), np.array(y_train)\n\n# Reshape the data\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n# x_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:24.196311Z","iopub.execute_input":"2023-04-17T19:46:24.197175Z","iopub.status.idle":"2023-04-17T19:46:24.209271Z","shell.execute_reply.started":"2023-04-17T19:46:24.197136Z","shell.execute_reply":"2023-04-17T19:46:24.207826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM\n\n# Build the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit(x_train, y_train, batch_size=50, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:46:24.211151Z","iopub.execute_input":"2023-04-17T19:46:24.211504Z","iopub.status.idle":"2023-04-17T19:47:20.497786Z","shell.execute_reply.started":"2023-04-17T19:46:24.21147Z","shell.execute_reply":"2023-04-17T19:47:20.496078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the testing data set\n# Create a new array containing scaled values from index 1543 to 2002 \ntest_data = scaled_data[training_data_len - 60: , :]\n# Create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])\n    \n# Convert the data to a numpy array\nx_test = np.array(x_test)\n\n# Reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n\n# Get the models predicted price values \npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\nrmse","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:20.499847Z","iopub.execute_input":"2023-04-17T19:47:20.500203Z","iopub.status.idle":"2023-04-17T19:47:21.800766Z","shell.execute_reply.started":"2023-04-17T19:47:20.50017Z","shell.execute_reply":"2023-04-17T19:47:21.799661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:21.802611Z","iopub.execute_input":"2023-04-17T19:47:21.803015Z","iopub.status.idle":"2023-04-17T19:47:21.81752Z","shell.execute_reply.started":"2023-04-17T19:47:21.80298Z","shell.execute_reply":"2023-04-17T19:47:21.81601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n# Visualize the data\nplt.figure(figsize=(16,6))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.plot(train['Close'])\nplt.plot(valid[['Close', 'Predictions']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:21.819037Z","iopub.execute_input":"2023-04-17T19:47:21.819363Z","iopub.status.idle":"2023-04-17T19:47:22.176257Z","shell.execute_reply.started":"2023-04-17T19:47:21.819331Z","shell.execute_reply":"2023-04-17T19:47:22.174945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ARIMA","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\n\nmodel = sm.tsa.arima.ARIMA(train_data, order=(1, 1, 1))  \nfitted = model.fit()\narima_preds = fitted.forecast(steps=len(test_data))\n\nprint(fitted.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fitted.forecast()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:51:56.540527Z","iopub.execute_input":"2023-04-17T19:51:56.541717Z","iopub.status.idle":"2023-04-17T19:51:56.554327Z","shell.execute_reply.started":"2023-04-17T19:51:56.541668Z","shell.execute_reply":"2023-04-17T19:51:56.552974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.arima.model import ARIMA\n\nmodel = ARIMA (train_data, order=(5,1,0))\nmodel_fit = model.fit()\n#print(model_fit.summary())\n\n# Make predictions using ARIMA\narima_preds = model.forecast(steps=len(test_data))[0]\n\n# Calculate RMSE and MAE for ARIMA\narima_rmse = np.sqrt(mean_squared_error(test_data['Close'], arima_preds))\narima_mae = mean_absolute_error(test_data['Close'], arima_preds)\nprint(f\"ARIMA RMSE: {arima_rmse:.2f}\")\nprint(f\"ARIMA MAE: {arima_mae:.2f}\")\n\n\n# plot residual errors\nresiduals = pd.DataFrame(model_fit.resid)\nresiduals.plot()\nplt.show()\nresiduals.plot(kind='kde')\nplt.show()\nprint (residuals.describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Plot the train data, test data, and ARIMA predictions\nplt.figure(figsize=(14, 6))\nplt.plot(data.index[:train_size], train_data['Close'], label='Train Data', color='blue')\nplt.plot(data.index[train_size:], test_data['Close'], label='Test Data', color='green')\nplt.plot(data.index[train_size:], arima_preds, label='ARIMA Predictions', color='red', linestyle='--')\nplt.xlabel('Date')\nplt.ylabel('Closing Price')\nplt.title('Tesla Closing Price with ARIMA Predictions')\nplt.legend()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima.model import ARIMA\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:23.963089Z","iopub.execute_input":"2023-04-17T19:47:23.963869Z","iopub.status.idle":"2023-04-17T19:47:24.96755Z","shell.execute_reply.started":"2023-04-17T19:47:23.963817Z","shell.execute_reply":"2023-04-17T19:47:24.966461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arima_model = ARIMA(train_data)#, order=best_pdq)\narima_model_fit = arima_model.fit()\n\n# Make predictions using ARIMA\narima_preds = arima_model_fit.forecast(steps=len(test_data))[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:24.968951Z","iopub.execute_input":"2023-04-17T19:47:24.969302Z","iopub.status.idle":"2023-04-17T19:47:25.113055Z","shell.execute_reply.started":"2023-04-17T19:47:24.969266Z","shell.execute_reply":"2023-04-17T19:47:25.111783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = seasonal_decompose(data, model='additive',period=365) # The frequncy is daily\nfigure = result.plot()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:25.114316Z","iopub.execute_input":"2023-04-17T19:47:25.114641Z","iopub.status.idle":"2023-04-17T19:47:26.109066Z","shell.execute_reply.started":"2023-04-17T19:47:25.11461Z","shell.execute_reply":"2023-04-17T19:47:26.107669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#valid = np.reshape(valid.Close.values, (valid.shape[0], valid.Close.shape[0], 1))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.116347Z","iopub.execute_input":"2023-04-17T19:47:26.117077Z","iopub.status.idle":"2023-04-17T19:47:26.122304Z","shell.execute_reply.started":"2023-04-17T19:47:26.117032Z","shell.execute_reply":"2023-04-17T19:47:26.121003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.124013Z","iopub.execute_input":"2023-04-17T19:47:26.124398Z","iopub.status.idle":"2023-04-17T19:47:26.147713Z","shell.execute_reply.started":"2023-04-17T19:47:26.12436Z","shell.execute_reply":"2023-04-17T19:47:26.146799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid.Close","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.149418Z","iopub.execute_input":"2023-04-17T19:47:26.150384Z","iopub.status.idle":"2023-04-17T19:47:26.160498Z","shell.execute_reply.started":"2023-04-17T19:47:26.150345Z","shell.execute_reply":"2023-04-17T19:47:26.158931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid['Close']","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.163283Z","iopub.execute_input":"2023-04-17T19:47:26.164847Z","iopub.status.idle":"2023-04-17T19:47:26.177341Z","shell.execute_reply.started":"2023-04-17T19:47:26.164784Z","shell.execute_reply":"2023-04-17T19:47:26.175889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.179251Z","iopub.execute_input":"2023-04-17T19:47:26.179685Z","iopub.status.idle":"2023-04-17T19:47:26.196158Z","shell.execute_reply.started":"2023-04-17T19:47:26.179648Z","shell.execute_reply":"2023-04-17T19:47:26.194501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.19777Z","iopub.execute_input":"2023-04-17T19:47:26.198207Z","iopub.status.idle":"2023-04-17T19:47:26.21334Z","shell.execute_reply.started":"2023-04-17T19:47:26.198171Z","shell.execute_reply":"2023-04-17T19:47:26.211667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train\nvalid = valid.Close\n\n\nhistory = [x for x in train]\npredictions = list('train')\n\n# walk-forward validation\nfor t in range(len(valid)):\n    model = ARIMA(history, order=(3,1,3))\n    model_fit = model.fit()\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.215047Z","iopub.execute_input":"2023-04-17T19:47:26.216314Z","iopub.status.idle":"2023-04-17T19:47:26.643075Z","shell.execute_reply.started":"2023-04-17T19:47:26.216257Z","shell.execute_reply":"2023-04-17T19:47:26.641795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate forecasts\nrolling_mse = mean_squared_error(test, predictions)\nprint('Test MSE: %.3f' % rolling_mse)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.644171Z","iopub.status.idle":"2023-04-17T19:47:26.645368Z","shell.execute_reply.started":"2023-04-17T19:47:26.645109Z","shell.execute_reply":"2023-04-17T19:47:26.645136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df_train['Close'].values\ntest = df_valid['Close'].values","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.646538Z","iopub.status.idle":"2023-04-17T19:47:26.647169Z","shell.execute_reply.started":"2023-04-17T19:47:26.646968Z","shell.execute_reply":"2023-04-17T19:47:26.646992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data[:training_data_len]\nvalid = data[training_data_len:]","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.648612Z","iopub.status.idle":"2023-04-17T19:47:26.649116Z","shell.execute_reply.started":"2023-04-17T19:47:26.648871Z","shell.execute_reply":"2023-04-17T19:47:26.648898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stocks_data=data\ndf_train = stocks_data[stocks_data.Date < 2021]\ndf_valid = stocks_data[stocks_data.Date >= 2021]","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.650287Z","iopub.status.idle":"2023-04-17T19:47:26.650882Z","shell.execute_reply.started":"2023-04-17T19:47:26.650504Z","shell.execute_reply":"2023-04-17T19:47:26.650575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df_train['Close'].values\ntest = df_valid['Close'].values","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.65248Z","iopub.status.idle":"2023-04-17T19:47:26.652934Z","shell.execute_reply.started":"2023-04-17T19:47:26.652689Z","shell.execute_reply":"2023-04-17T19:47:26.652716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = [x for x in train]\npredictions = list()\n\n# walk-forward validation\nfor t in range(len(valid)):\n    model = ARIMA(history, order=(3,1,3))\n    model_fit = model.fit()\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test[t]\n    history.append(obs)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.654859Z","iopub.status.idle":"2023-04-17T19:47:26.655278Z","shell.execute_reply.started":"2023-04-17T19:47:26.655072Z","shell.execute_reply":"2023-04-17T19:47:26.655095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TimeSeriesTransformer","metadata":{}},{"cell_type":"code","source":"self.encoder_input_layer = nn.Linear(\n  in_features=input_size, \n  out_features=dim_val\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.657741Z","iopub.status.idle":"2023-04-17T19:47:26.658483Z","shell.execute_reply.started":"2023-04-17T19:47:26.658248Z","shell.execute_reply":"2023-04-17T19:47:26.658276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Positional Encoder\n\nimport torch\nimport torch.nn as nn \nimport math\nfrom torch import nn, Tensor\n\nclass PositionalEncoder(nn.Module):\n    \"\"\"\n    The authors of the original transformer paper describe very succinctly what \n    the positional encoding layer does and why it is needed:\n    \n    \"Since our model contains no recurrence and no convolution, in order for the \n    model to make use of the order of the sequence, we must inject some \n    information about the relative or absolute position of the tokens in the \n    sequence.\" (Vaswani et al, 2017)\n    Adapted from: \n    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n    \"\"\"\n\n    def __init__(\n        self, \n        dropout: float=0.1, \n        max_seq_len: int=5000, \n        d_model: int=512,\n        batch_first: bool=False\n        ):\n\n        \"\"\"\n        Parameters:\n            dropout: the dropout rate\n            max_seq_len: the maximum length of the input sequences\n            d_model: The dimension of the output of sub-layers in the model \n                     (Vaswani et al, 2017)\n        \"\"\"\n\n        super().__init__()\n\n        self.d_model = d_model\n        \n        self.dropout = nn.Dropout(p=dropout)\n\n        self.batch_first = batch_first\n\n        self.x_dim = 1 if batch_first else 0\n\n        # copy pasted from PyTorch tutorial\n        position = torch.arange(max_seq_len).unsqueeze(1)\n        \n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        \n        pe = torch.zeros(max_seq_len, 1, d_model)\n        \n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        \n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        \n        self.register_buffer('pe', pe)\n        \n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"\n        Args:\n            x: Tensor, shape [batch_size, enc_seq_len, dim_val] or \n               [enc_seq_len, batch_size, dim_val]\n        \"\"\"\n\n        x = x + self.pe[:x.size(self.x_dim)]\n\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.659684Z","iopub.status.idle":"2023-04-17T19:47:26.660423Z","shell.execute_reply.started":"2023-04-17T19:47:26.660203Z","shell.execute_reply":"2023-04-17T19:47:26.660229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Positional Encoder\n\nimport positional_encoder as pe\n\n# Create positional encoder\nself.positional_encoding_layer = pe.PositionalEncoder(\n    d_model=dim_val,\n    dropout=dropout_pos_enc,\n    max_seq_len=max_seq_len\n    )\n\n#The encoder input layer produces an output of size dim_val.","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.662287Z","iopub.status.idle":"2023-04-17T19:47:26.662936Z","shell.execute_reply.started":"2023-04-17T19:47:26.662694Z","shell.execute_reply":"2023-04-17T19:47:26.662733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an encoder layer\n\nencoder_layer = nn.TransformerEncoderLayer(\n    d_model=dim_val,\n    nhead=n_heads, \n    batch_first=True\n    )\n\n# Stack the encoder layer n times in nn.TransformerDecoder\nself.encoder = nn.TransformerEncoder(\n    encoder_layer=encoder_layer,\n    num_layers=n_encoder_layers, \n    norm=None\n)\n\nself.decoder_input_layer = nn.Linear(\n  in_features=num_predicted_features, # the number of features you want to predict. Usually just 1 \n  out_features=dim_val\n) ","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.664577Z","iopub.status.idle":"2023-04-17T19:47:26.665424Z","shell.execute_reply.started":"2023-04-17T19:47:26.66521Z","shell.execute_reply":"2023-04-17T19:47:26.665235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Create the decoder layer\ndecoder_layer = nn.TransformerDecoderLayer(\n  d_model=dim_val, \n  nhead=n_heads,\n  batch_first=True\n  )\n\n# Stack the decoder layer n times\nself.decoder = nn.TransformerDecoder(\n  decoder_layer=decoder_layer,\n  num_layers=n_decoder_layers, \n  norm=None\n  )\n\nself.linear_mapping = nn.Linear(\n  in_features=dim_val,\n  out_features=num_predicted_features\n  )","metadata":{"execution":{"iopub.status.busy":"2023-04-17T19:47:26.666523Z","iopub.status.idle":"2023-04-17T19:47:26.667147Z","shell.execute_reply.started":"2023-04-17T19:47:26.666934Z","shell.execute_reply":"2023-04-17T19:47:26.666957Z"},"trusted":true},"execution_count":null,"outputs":[]}]}